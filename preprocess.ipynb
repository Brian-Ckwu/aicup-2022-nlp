{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from arguments import PreprocessArgs\n",
    "from preprocess import Preprocessor\n",
    "\n",
    "train_data_path = Path(\"./dataset/train.csv\")\n",
    "train_data = pd.read_csv(train_data_path).drop([\"Unnamed: 6\", \"total no.: 7987\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>q'</th>\n",
       "      <th>r'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"can go both ways . We all doubt . It is what ...</td>\n",
       "      <td>\"True\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>\"based on the idea that people are dispensible...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"seem to support the killing of certain people\"</td>\n",
       "      <td>\"based on the idea that people are dispensible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>\"based on the idea that people are dispensible...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"you seem to support the killing of certain pe...</td>\n",
       "      <td>\"based on the idea that people are dispensible\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38341</th>\n",
       "      <td>10001</td>\n",
       "      <td>\"good thing this argument has never been done ...</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"You are much better off making theft legal an...</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38342</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"I know one thing , anything that happens , po...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"I know one thing , anything that happens , po...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38343</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"I know one thing , anything that happens , po...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"FBI Arrests Three Men in Terror Plot that Tar...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38344</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"I enjoy Botany more than most things and I ha...</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"I enjoy Botany more than most things and I ha...</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38345</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"I enjoy Botany more than most things and I ha...</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"bringing in outside sun light through fiber o...</td>\n",
       "      <td>\"might give you an idea about costs and concep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38346 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                  q  \\\n",
       "0          8  \"It can go both ways . We all doubt . It is wh...   \n",
       "1          8  \"It can go both ways . We all doubt . It is wh...   \n",
       "2          8  \"It can go both ways . We all doubt . It is wh...   \n",
       "3          9  \"once again , you seem to support the killing ...   \n",
       "4          9  \"once again , you seem to support the killing ...   \n",
       "...      ...                                                ...   \n",
       "38341  10001  \"good thing this argument has never been done ...   \n",
       "38342  10002  \"I know one thing , anything that happens , po...   \n",
       "38343  10002  \"I know one thing , anything that happens , po...   \n",
       "38344  10003  \"I enjoy Botany more than most things and I ha...   \n",
       "38345  10003  \"I enjoy Botany more than most things and I ha...   \n",
       "\n",
       "                                                       r         s  \\\n",
       "0                                               \"True .\"     AGREE   \n",
       "1                                               \"True .\"     AGREE   \n",
       "2                                               \"True .\"     AGREE   \n",
       "3      \"based on the idea that people are dispensible...     AGREE   \n",
       "4      \"based on the idea that people are dispensible...     AGREE   \n",
       "...                                                  ...       ...   \n",
       "38341  \"And teen sex does n't , by the very nature of...  DISAGREE   \n",
       "38342  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "38343  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "38344  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "38345  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "\n",
       "                                                      q'  \\\n",
       "0      \"It can go both ways . We all doubt . It is wh...   \n",
       "1      \"can go both ways . We all doubt . It is what ...   \n",
       "2      \"It can go both ways . We all doubt . It is wh...   \n",
       "3        \"seem to support the killing of certain people\"   \n",
       "4      \"you seem to support the killing of certain pe...   \n",
       "...                                                  ...   \n",
       "38341  \"You are much better off making theft legal an...   \n",
       "38342  \"I know one thing , anything that happens , po...   \n",
       "38343  \"FBI Arrests Three Men in Terror Plot that Tar...   \n",
       "38344  \"I enjoy Botany more than most things and I ha...   \n",
       "38345  \"bringing in outside sun light through fiber o...   \n",
       "\n",
       "                                                      r'  \n",
       "0                                               \"True .\"  \n",
       "1                                                 \"True\"  \n",
       "2                                                 \"True\"  \n",
       "3      \"based on the idea that people are dispensible...  \n",
       "4        \"based on the idea that people are dispensible\"  \n",
       "...                                                  ...  \n",
       "38341  \"And teen sex does n't , by the very nature of...  \n",
       "38342  \"Was n't sinjin crowing about his plans to tak...  \n",
       "38343  \"Was n't sinjin crowing about his plans to tak...  \n",
       "38344  \"Hi Smallax , welcome to the forum . I did a s...  \n",
       "38345  \"might give you an idea about costs and concep...  \n",
       "\n",
       "[38346 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schemes = PreprocessArgs.input_schemes\n",
    "output_schemes = PreprocessArgs.output_schemes\n",
    "labeling_schemes = PreprocessArgs.labeling_schemes # 1: use the same class for q' and r' / 2: use different classes (e.g., I-q and I-r) for q' and r'\n",
    "\n",
    "args = PreprocessArgs(\n",
    "    use_nltk=False,\n",
    "    model_tokenizer_name=\"bert-base-uncased\",\n",
    "    input_scheme=\"qr\",\n",
    "    output_scheme=\"q'r'\",\n",
    "    labeling_scheme=\"IO1\"\n",
    ")\n",
    "\n",
    "preprocessor = Preprocessor(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:02,  5.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "debug_sample_size = 100\n",
    "\n",
    "for i, (ip, op, lbl) in tqdm(enumerate(itertools.product(input_schemes, output_schemes, labeling_schemes))):\n",
    "    args = PreprocessArgs(\n",
    "        use_nltk=False,\n",
    "        model_tokenizer_name=\"bert-base-uncased\",\n",
    "        input_scheme=ip,\n",
    "        output_scheme=op,\n",
    "        labeling_scheme=lbl\n",
    "    )\n",
    "    preprocessor.set_args(args)\n",
    "\n",
    "    p_data = preprocessor(train_data.iloc[:debug_sample_size])\n",
    "    \n",
    "    save_path = Path(f\"./dataset/p{i}\")\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    p_data.to_csv(save_path / \"data.csv\", index=False)\n",
    "    (save_path / \"pargs.json\").write_text(json.dumps(vars(args), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R, S, QP, RP = [train_data[field] for field in [\"q\", \"r\", \"s\", \"q'\", \"r'\"]]\n",
    "\n",
    "for input_scheme in PreprocessArgs.input_schemes:\n",
    "    for output_scheme in PreprocessArgs.output_schemes:\n",
    "        for labeling_scheme in PreprocessArgs.labeling_schemes:\n",
    "            args = PreprocessArgs(\n",
    "                use_nltk=False,\n",
    "                model_tokenizer_name=\"bert-base-uncased\",\n",
    "                input_scheme=input_scheme,\n",
    "                output_scheme=output_scheme,\n",
    "                labeling_scheme=labeling_scheme\n",
    "            )\n",
    "            print(f\"\\nScheme: {input_scheme} / {output_scheme} / {labeling_scheme}\\n\")\n",
    "            preprocessor.set_args(args)\n",
    "\n",
    "            index = 15\n",
    "\n",
    "            q = preprocessor.model_tokenize(Q[index])\n",
    "            r = preprocessor.model_tokenize(R[index])\n",
    "            s = S[index]\n",
    "            qp = preprocessor.label_sequence(q, preprocessor.model_tokenize(QP[index]))\n",
    "            rp = preprocessor.label_sequence(r, preprocessor.model_tokenize(RP[index]))\n",
    "\n",
    "            X, y = preprocessor.format_data(q, r, s, qp, rp)\n",
    "\n",
    "            if type(y) == tuple:\n",
    "                y_cls, y_seq = y\n",
    "                print(f\"y_cls: {y_cls}\")\n",
    "            else:\n",
    "                y_seq = y\n",
    "\n",
    "            print(f\"X: {X} -> {' '.join(preprocessor.model_tokenizer.convert_ids_to_tokens(X))}\")\n",
    "            print(f\"y: {y_seq} -> {' '.join(preprocessor.model_tokenizer.convert_ids_to_tokens(np.array(X)[np.array(y_seq) != 0]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases for add_labels_by_two\n",
    "by_two_cases = [\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 1],\n",
    "    [0, 1, 0, 0, 1]\n",
    "]\n",
    "\n",
    "by_two_answers = list(map(preprocessor.add_labels_by_two, by_two_cases))\n",
    "\n",
    "# add_B_to_labels\n",
    "add_B_cases = [\n",
    "    # 1\n",
    "    [-100, 0, 1, 1, -100, 1, 1, 0, -100],\n",
    "    [-100, 0, 0, 0, -100, 0, 1, 0, -100, -100, -100],\n",
    "    [-100, 1, 1, 1, -100, 1, 0, 1, -100],\n",
    "    # 2\n",
    "    [-100, 1, 1, 0, -100, 3, 3, 3, -100, -100, -100],\n",
    "    [-100, 1, 0, 1, 1, -100, 3, 0, 3, -100],\n",
    "    [-100, 1, 0, 1, -100, 0, 3, 3, -100]\n",
    "]\n",
    "\n",
    "add_B_cases = list(map(preprocessor.add_B_to_labels, add_B_cases))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda-11.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35b66dd0c8f752918e1728d86abaa8fb004a7dee1d90779ea4d0023d852f9fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
